{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medical Cost Personal Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Understanding Data:\n",
    "**Columns:**\n",
    "* Features (labels or independent variables or predictors) [7]:\n",
    "  * age: age of primary beneficiary\n",
    "\n",
    "  * sex: insurance contractor gender, female, male\n",
    "\n",
    "  * bmi: Body mass index, providing an understanding of body, weights that are relatively high or low relative to height, objective index of body weight (kg / m ^ 2) using the ratio of height to weight, ideally 18.5 to 24.9\n",
    "\n",
    "  * children: Number of children covered by health insurance / Number of dependents\n",
    "\n",
    "  * smoker: Smoking\n",
    "\n",
    "  * region: the beneficiary's residential area in the US, northeast, southeast, southwest, northwest.\n",
    "\n",
    "* Output (dependent variable or to-predict)\n",
    "  * charges: Individual medical costs billed by health insurance\n",
    "\n",
    "**Inspiration:**\n",
    "Can you accurately predict insurance costs?\n",
    "\n",
    "**Reference to raw csv file:** https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/refs/heads/master/insurance.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# import plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n",
    "from IPython.display import display\n",
    "\n",
    "# model visualizatio library\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "random_seed=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the csv data using pandas\n",
    "dataset=pd.read_csv('dataset.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: one-hot encode all categorical features\n",
    "dataset_ohe=pd.get_dummies(dataset)\n",
    "dataset_ohe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Split the features and labels\n",
    "X = dataset_ohe.drop('charges',axis=1) # axis = 1 is for columnwise\n",
    "print(X.columns)\n",
    "\n",
    "# y=dataset_ohe['charges'] \n",
    "y=dataset_ohe.drop(X.columns,axis=1) \n",
    "print(y.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view X\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view y\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=random_seed)\n",
    "len(X),len(X_train),len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view X_train\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns,X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Details after pre-processing**\n",
    "* Total input features: 11 <br>\n",
    "    X = ['age', 'bmi', 'children', 'sex_female', 'sex_male', 'smoker_no', 'smoker_yes', 'region_northeast', 'region_northwest','region_southeast', 'region_southwest']\n",
    "* Total output features: 1 <br>\n",
    "    y = ['charges']\n",
    "\n",
    "**Note:** \n",
    "* We don't need to convert it to tensors as pandas is built on numpy, and tensorflow also, hence it excepts them as it is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Building the neural network for regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the random seed\n",
    "tf.random.set_seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparams:\n",
    "learning_rate=0.1\n",
    "epochs=100\n",
    "\n",
    "# creating the model:\n",
    "model1=tf.keras.Sequential(name=\"model_mcp_1\")\n",
    "\n",
    "# adding 2 hidden layers (each with 10 neurons) and output layer with 1 neuron\n",
    "model1.add(tf.keras.layers.Dense(10,input_shape=[11],activation='relu',name='hidden_layer_1'))\n",
    "model1.add(tf.keras.layers.Dense(10,activation='relu',name='hidden_layer_2'))\n",
    "model1.add(tf.keras.layers.Dense(1,name='output_layer'))\n",
    "\n",
    "# compiling the model\n",
    "model1.compile(\n",
    "    loss='mse',\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "    metrics=['mse']\n",
    ")\n",
    "\n",
    "# visulize model and get summary\n",
    "\n",
    "display(plot_model(\n",
    "    model=model1,\n",
    "    show_dtype=False,\n",
    "    show_shapes=True, \n",
    "    rankdir='TB',  # 'TB' for top-to-bottom layout, 'LR' for left-to-right\n",
    "    show_layer_names=True,  # Optional: Shows layer names\n",
    "    dpi=70,  # Reduce DPI to make it smaller\n",
    "    expand_nested=True,  # Optional: Expands nested models if present\n",
    "    show_layer_activations=True,\n",
    "    show_trainable=True,\n",
    "    # to_file='model.png' # File name of the plot image,\n",
    "))\n",
    "\n",
    "display(model1.summary())\n",
    "\n",
    "# fitting the model\n",
    "history1 = model1.fit(X_train,y_train,epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating model1:\n",
    "# plot history (loss curve or training curve)\n",
    "pd.DataFrame(history1.history).plot(figsize=(4,3),xlabel=\"Epochs\",ylabel=\"MSE-loss\",legend=False);\n",
    "\n",
    "# evaluating using MAE:\n",
    "print(f\"MAE loss: {tf.metrics.mae(tf.squeeze(y_test),tf.squeeze(model1.predict(X_test,verbose=0))).numpy()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparams:\n",
    "learning_rate=0.1\n",
    "epochs=200\n",
    "\n",
    "# creating the model:\n",
    "model1=tf.keras.Sequential(name=\"model_mcp_1\")\n",
    "\n",
    "# adding 2 hidden layers (each with 10 neurons) and output layer with 1 neuron\n",
    "model1.add(tf.keras.layers.Dense(100,input_shape=[11],activation='relu',name='hidden_layer_1'))\n",
    "model1.add(tf.keras.layers.Dense(100,activation='relu',name='hidden_layer_2'))\n",
    "model1.add(tf.keras.layers.Dense(1,name='output_layer'))\n",
    "\n",
    "# compiling the model\n",
    "model1.compile(\n",
    "    loss='mse',\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "    metrics=['mse']\n",
    ")\n",
    "\n",
    "# visulize model and get summary\n",
    "\n",
    "display(plot_model(\n",
    "    model=model1,\n",
    "    show_dtype=False,\n",
    "    show_shapes=True, \n",
    "    rankdir='TB',  # 'TB' for top-to-bottom layout, 'LR' for left-to-right\n",
    "    show_layer_names=True,  # Optional: Shows layer names\n",
    "    dpi=70,  # Reduce DPI to make it smaller\n",
    "    expand_nested=True,  # Optional: Expands nested models if present\n",
    "    show_layer_activations=True,\n",
    "    show_trainable=True,\n",
    "    # to_file='model.png' # File name of the plot image,\n",
    "))\n",
    "\n",
    "display(model1.summary())\n",
    "\n",
    "# fitting the model\n",
    "history2 = model1.fit(X_train,y_train,epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating model1:\n",
    "# plot history (loss curve or training curve)\n",
    "pd.DataFrame(history2.history).plot(figsize=(4,3),xlabel=\"Epochs\",ylabel=\"MSE-loss\",legend=False);\n",
    "\n",
    "# evaluating using MAE:\n",
    "print(f\"MAE loss: {tf.metrics.mae(tf.squeeze(y_test),tf.squeeze(model1.predict(X_test,verbose=0))).numpy()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion: Our current model is not performing too well, it needs improvements**\n",
    "<br>\n",
    "<br>\n",
    "`Continued in next notebook`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
