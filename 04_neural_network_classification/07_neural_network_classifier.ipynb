{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Neural Network Classification in Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DL needs\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as kr\n",
    "\n",
    "# Data needs\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Numerical computation needs\n",
    "import numpy as np\n",
    "\n",
    "# plotting needs\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n",
    "\n",
    "# ensuring reproducibility\n",
    "random_seed=42\n",
    "tf.random.set_seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Improving Predictions on Fashion MNIST using normalized data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "(train_data, train_labels),(test_data,test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dictationary of labels:\n",
    "labels = ['T-shirt/top', \n",
    "          'Trouser', \n",
    "          'Pullover',\n",
    "          'Dress',   \n",
    "          'Coat',    \n",
    "          'Sandal',  \n",
    "          'Shirt',   \n",
    "          'Sneaker', \n",
    "          'Bag',     \n",
    "          'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 , 1.0\n",
      "0.0 , 1.0\n"
     ]
    }
   ],
   "source": [
    "# normalizing data\n",
    "train_data_norm=(train_data-train_data.min())/train_data.max()\n",
    "test_data_norm=(test_data-test_data.min())/test_data.max()\n",
    "print(train_data_norm[0].min(),\",\",train_data_norm[0].max())\n",
    "print(test_data_norm[0].min(),\",\",test_data_norm[0].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(5, 10), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]], shape=(5, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# one-hot encode labels\n",
    "train_labels_ohe=tf.one_hot(train_labels,len(labels))\n",
    "print(train_labels_ohe[:5])\n",
    "test_labels_ohe=tf.one_hot(test_labels,len(labels))\n",
    "print(test_labels_ohe[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a model\n",
    "\n",
    "class FashionNet(kr.Model):\n",
    "    def __init__(self,lr=0.001,model_name=\"model_1\",metrics=['accuracy']):\n",
    "        super().__init__(name=model_name)\n",
    "        # instantiating constructor of parent class\n",
    "\n",
    "        # input layer:\n",
    "        self.input_layer=tf.keras.Input(shape=[28,28],name='input_layer')\n",
    "        \n",
    "        # flattening the input\n",
    "        self.flatten=kr.layers.Flatten(input_shape=(28,28),name='flatten')\n",
    "\n",
    "        # hidden layer:\n",
    "        self.fc1 = kr.layers.Dense(4,activation=None,name='hl1')\n",
    "        self.fc2 = kr.layers.Dense(4,activation=None,name='hl2')\n",
    "        # self.fc3 = kr.layers.Dense(4,activation=None,name='hl3')\n",
    "\n",
    "        self.layer_activations={\n",
    "            \"flatten\":None,\n",
    "            \"hl1\":'ReLU',\n",
    "            \"hl2\":'ReLU',\n",
    "            \"output_layer\":\"Softmax\"\n",
    "        }\n",
    "\n",
    "        # output layer\n",
    "        self.output_layer=kr.layers.Dense(10,activation=None,name='output_layer')\n",
    "\n",
    "\n",
    "        # other hyper-params\n",
    "        self.loss_function=\"categorical_crossentropy\"\n",
    "        self.optimizer=kr.optimizers.Adam(learning_rate=lr)\n",
    "        self.eval_metrics=metrics\n",
    "\n",
    "    def call(self,inputs):\n",
    "        # forward propogation\n",
    "        x=self.flatten(inputs)\n",
    "        x=tf.nn.relu(self.fc1(x))\n",
    "        x=tf.nn.relu(self.fc2(x))\n",
    "        # x=tf.nn.relu(self.fc3(x))\n",
    "        output=tf.nn.softmax(self.output_layer(x))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rudraksha14/.local/lib/python3.10/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"model_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"model_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ hl1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,140</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ hl2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ hl1 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │         \u001b[38;5;34m3,140\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ hl2 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m20\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │            \u001b[38;5;34m50\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,210</span> (12.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,210\u001b[0m (12.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,210</span> (12.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,210\u001b[0m (12.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 18:04:30.376184: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 188160000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4963 - loss: 1.3995 - val_accuracy: 0.7278 - val_loss: 0.7893\n",
      "Epoch 2/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7417 - loss: 0.7440 - val_accuracy: 0.7656 - val_loss: 0.6848\n",
      "Epoch 3/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7749 - loss: 0.6477 - val_accuracy: 0.7815 - val_loss: 0.6297\n",
      "Epoch 4/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7910 - loss: 0.5996 - val_accuracy: 0.7914 - val_loss: 0.6071\n",
      "Epoch 5/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7985 - loss: 0.5775 - val_accuracy: 0.7981 - val_loss: 0.5945\n",
      "Epoch 6/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8050 - loss: 0.5632 - val_accuracy: 0.7990 - val_loss: 0.5871\n",
      "Epoch 7/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8099 - loss: 0.5531 - val_accuracy: 0.8012 - val_loss: 0.5818\n",
      "Epoch 8/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8126 - loss: 0.5454 - val_accuracy: 0.8032 - val_loss: 0.5767\n",
      "Epoch 9/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8148 - loss: 0.5384 - val_accuracy: 0.8037 - val_loss: 0.5735\n",
      "Epoch 10/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8165 - loss: 0.5319 - val_accuracy: 0.8030 - val_loss: 0.5707\n",
      "Epoch 11/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8185 - loss: 0.5255 - val_accuracy: 0.8038 - val_loss: 0.5707\n",
      "Epoch 12/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8199 - loss: 0.5202 - val_accuracy: 0.8030 - val_loss: 0.5688\n",
      "Epoch 13/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8206 - loss: 0.5149 - val_accuracy: 0.8045 - val_loss: 0.5689\n",
      "Epoch 14/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8219 - loss: 0.5106 - val_accuracy: 0.8057 - val_loss: 0.5678\n",
      "Epoch 15/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8240 - loss: 0.5061 - val_accuracy: 0.8048 - val_loss: 0.5660\n",
      "Epoch 16/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8255 - loss: 0.5019 - val_accuracy: 0.8055 - val_loss: 0.5611\n",
      "Epoch 17/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8268 - loss: 0.4983 - val_accuracy: 0.8070 - val_loss: 0.5578\n",
      "Epoch 18/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8282 - loss: 0.4952 - val_accuracy: 0.8095 - val_loss: 0.5561\n",
      "Epoch 19/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8299 - loss: 0.4922 - val_accuracy: 0.8099 - val_loss: 0.5555\n",
      "Epoch 20/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8307 - loss: 0.4894 - val_accuracy: 0.8122 - val_loss: 0.5504\n"
     ]
    }
   ],
   "source": [
    "# fitting the model\n",
    "model_1 = FashionNet(model_name='model_1',lr=0.001)\n",
    "model_1(tf.keras.Input(shape=[28,28]))  \n",
    "model_1.compile(loss=model_1.loss_function,optimizer=model_1.optimizer,metrics=model_1.eval_metrics)\n",
    "model_1.summary()\n",
    "history_2=model_1.fit(train_data_norm,train_labels_ohe,epochs=20,validation_data=(test_data_norm,test_labels_ohe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9. Understanding patterns learnt by our model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* by default the weights in the keras.layers.Dense is initialized using `kernel_initializer = 'glorot_uniform'` and the bias vectors is initialized to zeros.\n",
    "* The bias vector dictates how much the pattern within the corresponding weights matrix should influence the next layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Flatten name=flatten, built=True>,\n",
       " <Dense name=hl1, built=True>,\n",
       " <Dense name=hl2, built=True>,\n",
       " <Dense name=output_layer, built=True>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the layers of model:\n",
    "model_1.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 4) (4,)\n",
      "[[ 0.09309386 -1.0883762   0.21780913  0.5602282 ]\n",
      " [-1.0112921  -0.19426206  0.5343483   1.0279362 ]\n",
      " [ 0.3673576  -1.3152485   0.5681249   0.83580977]\n",
      " ...\n",
      " [-0.33126888 -0.13971567  0.04316235 -0.33810866]\n",
      " [-0.28372085 -0.14338706 -0.14433335 -0.6756599 ]\n",
      " [-0.02092897 -0.5624809   0.13253969  0.85101223]] [0.19855566 0.63483083 0.34453633 0.54407555]\n"
     ]
    }
   ],
   "source": [
    "# extract a particular layer and inspecting weights and biases\n",
    "hl1=model_1.layers[1]\n",
    "weight_1,bias_1=hl1.get_weights()\n",
    "\n",
    "# printing shapes of weights and biases\n",
    "print(weight_1.shape,bias_1.shape)\n",
    "print(weight_1,bias_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model.png'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphviz\n",
    "import tensorflow as tf\n",
    "\n",
    "def plot_custom_model(model, input_shape, show_shapes=True, show_activations=True,          \n",
    "                      show_trainable_status=True,graph_size=\"8,8\", dpi=100, node_width=\"1.5\", node_height=\"0.5\",ranksep=\"0.5\", nodesep=\"0.3\", title=\"Model Architecture\", save_path=None):\n",
    "    \"\"\"\n",
    "    Plots a detailed visualization of a subclassed Keras model with structured sections\n",
    "    and different colours for each row while maintaining a single rectangle per layer.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The Keras model to visualize.\n",
    "    - input_shape: The expected input shape (excluding batch size).\n",
    "    - show_shapes: Whether to display layer shapes.\n",
    "    - show_activations: Whether to display activation functions.\n",
    "    - show_trainable_status: Whether to display trainable status.\n",
    "    - graph_size: The overall size of the graph (e.g., \"8,8\").\n",
    "    - dpi: Resolution of the graph (higher = sharper but larger).\n",
    "    - node_width: Width of each node.\n",
    "    - node_height: Height of each node.\n",
    "    - ranksep: Vertical spacing between layers.\n",
    "    - nodesep: Horizontal spacing between nodes.\n",
    "    - title: Title displayed at the top of the graph.\n",
    "    - save_path: If specified, saves the plot as a PNG file.\n",
    "    \"\"\"\n",
    "    dot = graphviz.Digraph(format='png')\n",
    "    \n",
    "    # Adjust graph properties\n",
    "    dot.attr(size=graph_size, dpi=str(dpi), nodesep=nodesep, ranksep=ranksep)\n",
    "    \n",
    "    # Add title at the top\n",
    "    dot.attr(label=f\"<<B>{title}</B>>\", labelloc=\"t\", fontsize=\"16\", fontcolor=\"black\",fontweight='bold')\n",
    "\n",
    "    prev_layer = None\n",
    "    x = tf.keras.layers.Input(shape=input_shape)\n",
    "\n",
    "    for layer in model.layers:\n",
    "        layer_name = layer.name\n",
    "        layer_type = type(layer).__name__\n",
    "\n",
    "        # Get activation function\n",
    "        activation = getattr(layer, \"activation\", None)\n",
    "        activation_name = activation.__name__ if activation else \"None\"\n",
    "\n",
    "        # Compute input & output shapes\n",
    "        try:\n",
    "            output_shape = layer.compute_output_shape(x.shape) if show_shapes else \"N/A\"\n",
    "        except Exception:\n",
    "            output_shape = \"Unknown\"\n",
    "\n",
    "        activation_name = activation_name if show_activations else \"N/A\"\n",
    "        # input_shape_str = str(x.shape) if show_shapes else \"N/A\"\n",
    "        trainable_status = \"Yes\" if layer.trainable else \"No\"\n",
    "\n",
    "        # Ensure each row exists properly even if not all options are enabled\n",
    "        act_row = f'<TR><TD COLSPAN=\"3\" BGCOLOR=\"lightgreen\">Activation: {activation_name}</TD></TR>' if show_activations else \"\"\n",
    "\n",
    "        shape_row = \"\"\n",
    "        if show_shapes:\n",
    "            shape_row += f'<TD BGCOLOR=\"lightyellow\"><B>Input</B>: {str(x.shape)}</TD>\\n'\n",
    "            shape_row += f'<TD BGCOLOR=\"lightpink\"><B>Output</B>: {output_shape}</TD>'\n",
    "        else:\n",
    "            shape_row += '<TD COLSPAN=\"2\"></TD>'  # Maintain table structure\n",
    "\n",
    "        train_stat_row = f'<TD BGCOLOR=\"lightgrey\"><B>Trainable</B>: {trainable_status}</TD>' if show_trainable_status else \"\"\n",
    "\n",
    "        # Ensure at least one row is always present\n",
    "        if not (show_shapes or show_trainable_status):\n",
    "            shape_row = '<TD COLSPAN=\"3\"></TD>'\n",
    "\n",
    "        # Table format with controlled spacing\n",
    "        label = f\"\"\"<\n",
    "        <TABLE BORDER=\"0\" CELLBORDER=\"1\" CELLSPACING=\"0\">\n",
    "            <TR><TD COLSPAN=\"3\" BGCOLOR=\"lightblue\"><B>{layer_name}</B> ({layer_type})</TD></TR>\n",
    "            {act_row}\n",
    "            <TR>\n",
    "                {shape_row}\n",
    "                {train_stat_row}\n",
    "            </TR>\n",
    "        </TABLE>\n",
    "        >\"\"\"\n",
    "\n",
    "        # Create the node with adjusted width/height\n",
    "        dot.node(layer_name, label=label, shape=\"plaintext\", width=node_width, height=node_height)\n",
    "\n",
    "        # Connect layers sequentially\n",
    "        if prev_layer:\n",
    "            dot.edge(prev_layer.name, layer_name)\n",
    "\n",
    "        prev_layer = layer\n",
    "        x = layer(x)  # Pass dummy input through each layer\n",
    "\n",
    "    if save_path:\n",
    "        dot.render(save_path, format=\"png\", cleanup=True)\n",
    "\n",
    "    return dot\n",
    "\n",
    "# Example usage with a title:\n",
    "dot_graph = plot_custom_model(model_1, input_shape=(28, 28), \n",
    "                              show_shapes=True, \n",
    "                              show_activations=True, \n",
    "                              show_trainable_status=True,\n",
    "                              graph_size=\"6,6\", dpi=300,  \n",
    "                              node_width=\"1.2\", node_height=\"0.5\",  \n",
    "                              ranksep=\"0.4\", nodesep=\"0.2\",  \n",
    "                              title=\"model_1\",\n",
    "                              save_path=\"model\")\n",
    "\n",
    "dot_graph.view()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
