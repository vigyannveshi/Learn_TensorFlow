{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-12 18:02:44.681722: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# DL needs\n",
    "import tensorflow as tf\n",
    "import keras as kr\n",
    "\n",
    "# Data needs\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Numerical computation needs\n",
    "import numpy as np\n",
    "\n",
    "# plotting needs\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n",
    "\n",
    "# ensuring reproducibility\n",
    "random_seed=42\n",
    "tf.random.set_seed(random_seed)\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/rudraksha14/Desktop/RAY_RISE_ABOVE_YOURSELF/Programming/tensorflow/')\n",
    "import important_functionalities as impf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data_dir='/home/rudraksha14/Desktop/RAY_RISE_ABOVE_YOURSELF/Programming/tensorflow/6_transfer_learning_feature_extraction/10_food_classes_10_percent'\n",
    "train_dir=data_dir+'/train'\n",
    "valid_dir=data_dir+'/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 750 files belonging to 10 classes.\n",
      "Found 2500 files belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SHAPE=(224,224)\n",
    "BATCH_SIZE=32\n",
    "train_data=tf.keras.preprocessing.image_dataset_from_directory(directory=train_dir,\n",
    "                                                               image_size=IMAGE_SHAPE,\n",
    "                                                               label_mode='categorical',\n",
    "                                                                batch_size=BATCH_SIZE\n",
    "                                                               )\n",
    "valid_data=tf.keras.preprocessing.image_dataset_from_directory(directory=valid_dir,\n",
    "                                                               image_size=IMAGE_SHAPE,\n",
    "                                                                label_mode='categorical',\n",
    "                                                                 batch_size=BATCH_SIZE\n",
    "                                                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Experiment | Data       | Preprocessing | Model          |\n",
    "|------------|------------|---------------|----------------|\n",
    "| Model 0<br>(baseline)     | 10 classes of food101 dataset (random 10% training data only)  | None        | Feature Extractor: EfficientNetB0 (pretrained on ImageNet, all layers frozen) with no top|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after base_model: (None, 7, 7, 1280)\n",
      "After GlobalAveragePooling2D(): (None, 1280)\n",
      "Saving TensorBoard log files to : transfer_learning/10_percent_feature_extraction/20250312-180427\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-12 18:04:35.156949: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 51380224 exceeds 10% of free system memory.\n",
      "2025-03-12 18:04:35.217100: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 51380224 exceeds 10% of free system memory.\n",
      "2025-03-12 18:04:35.318741: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 51380224 exceeds 10% of free system memory.\n",
      "2025-03-12 18:04:35.361255: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 51380224 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/24\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:15\u001b[0m 8s/step - accuracy: 0.1250 - loss: 2.4220"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-12 18:04:36.071281: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 51380224 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.2744 - loss: 2.1213 - val_accuracy: 0.7368 - val_loss: 1.3092\n",
      "Epoch 2/5\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - accuracy: 0.7194 - loss: 1.2431 - val_accuracy: 0.8306 - val_loss: 0.8809\n",
      "Epoch 3/5\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1s/step - accuracy: 0.8149 - loss: 0.8399 - val_accuracy: 0.8421 - val_loss: 0.7113\n",
      "Epoch 4/5\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1s/step - accuracy: 0.8448 - loss: 0.6997 - val_accuracy: 0.8470 - val_loss: 0.6304\n",
      "Epoch 5/5\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1s/step - accuracy: 0.8760 - loss: 0.5899 - val_accuracy: 0.8536 - val_loss: 0.5657\n"
     ]
    }
   ],
   "source": [
    "# Model 0: Building a transfer learning model using Keras Functional API\n",
    "\n",
    "### 1. Create the base model with tf.keras.applications\n",
    "base_model=tf.keras.applications.efficientnet_v2.EfficientNetV2B0(include_top=False,#exclude o/p layer\n",
    "                                                                  weights='imagenet',\n",
    "                                                                 input_shape=(224,224,3)) \n",
    "\n",
    "### 2. Freeze the layers in the base model\n",
    "base_model.trainable=False\n",
    "\n",
    "### 3. Create inputs into our model\n",
    "inputs = tf.keras.layers.Input(shape=(224,224,3),name='input_layer')    \n",
    "\n",
    "### 4. If using a model like ResNet50V2 you will need to normalize inputs (you don't have to for EfficientNet)\n",
    "# x = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)(inputs)\n",
    "\n",
    "### 5. Pass the inputs to the base_model\n",
    "x = base_model(inputs)\n",
    "print(f\"Shape after base_model: {x.shape}\")\n",
    "\n",
    "### 6. max pool the outputs of the base model (aggregate all the most important information, reduce number of computations)\n",
    "x = tf.keras.layers.GlobalmaxPooling2D(name='global_max_pooling_layer')(x)\n",
    "print(f\"After GlobalmaxPooling2D(): {x.shape}\")\n",
    "\n",
    "### 7. Create the output activation layer\n",
    "outputs = tf.keras.layers.Dense(10,activation='softmax',name='output_layer')(x)\n",
    "\n",
    "### 8. Combine the inputs with the outputs into a model\n",
    "model_0=tf.keras.Model(inputs,outputs)\n",
    "\n",
    "\n",
    "### 9. Compile the model\n",
    "model_0.compile(loss='categorical_crossentropy',\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "### 10. Fit the model and save its history\n",
    "history_10_percent=model_0.fit(train_data,\n",
    "                               epochs=5,\n",
    "                               steps_per_epoch=len(train_data),\n",
    "                               validation_data=valid_data,\n",
    "                               validation_steps=int(0.25*len(valid_data)),\n",
    "                               callbacks=[impf.create_tensorboard_callback(dir_name=\"transfer_learning\",     experiment_name=\"10_percent_feature_extraction\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 694ms/step - accuracy: 0.8490 - loss: 0.5770\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.579102635383606, 0.8507999777793884]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate on complete validation data\n",
    "model_0.evaluate(valid_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2. Getting feature vector from trained model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To demonstrate the Global max Pooling 2D layer \n",
    "  * We have a tensor after our model goes through `base_model` of shape (None,7,7,1280) ....\n",
    "  * When we pass this through Global max Pooling 2D layer, it turns into (None,1280)\n",
    "  * Let's use a similar shape tensor of (1,4,4,3) and then pass it through GlobalmaxPooling2D {transforms a 4D tensor into a 2D tensor}\n",
    "* A feature vector is a learned representation of the input data (a compressed form of the input data based on how the model sees it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random input tensor:\n",
      " [[[[-0.23585585  0.33401316  0.6599627 ]\n",
      "   [ 1.1498349   0.80851334  1.9857812 ]\n",
      "   [ 0.24859004  0.6843617  -1.4259181 ]\n",
      "   [ 1.4124185   0.9517439   1.7974569 ]]\n",
      "\n",
      "  [[-0.37729186  0.3015694   0.4366594 ]\n",
      "   [ 1.2700577   0.326862   -0.4133045 ]\n",
      "   [ 1.1873597  -0.5737731  -0.17353044]\n",
      "   [-0.5922727  -0.27917758  0.89432085]]\n",
      "\n",
      "  [[ 0.4163104  -0.23119776  0.20691264]\n",
      "   [ 1.5541818  -1.1967332  -1.6391214 ]\n",
      "   [ 0.15168859  1.4021907  -1.5639578 ]\n",
      "   [ 1.4441936  -0.17168391 -0.4327975 ]]\n",
      "\n",
      "  [[ 0.93174577 -0.077992   -0.56287485]\n",
      "   [ 0.6456059  -0.60841733  0.7858203 ]\n",
      "   [-0.77531946  0.68973136 -0.56853956]\n",
      "   [-0.445213   -1.2932749   1.0399288 ]]]]\n",
      "\n",
      "2D global average pooled random tensor:\n",
      " [[0.49912712 0.06667098 0.06417489]]\n",
      "\n",
      "Shape of input tensor: (1, 4, 4, 3)\n",
      "Shape of 2D global average pooled random tensor: (1, 3)\n"
     ]
    }
   ],
   "source": [
    "input_shape=(1,4,4,3)\n",
    "\n",
    "# create a random tensor\n",
    "input_tensor=tf.random.normal(input_shape)\n",
    "print(f\"Random input tensor:\\n {input_tensor}\\n\")\n",
    "\n",
    "# pass the random tensor through a global max pooling 2D layer\n",
    "global_max_pooled_tensor=tf.keras.layers.GlobalmaxPooling2D()(input_tensor)\n",
    "print(f\"2D global max pooled random tensor:\\n {global_max_pooled_tensor}\\n\")\n",
    "\n",
    "# check the shape\n",
    "print(f\"Shape of input tensor: {input_tensor.shape}\")\n",
    "print(f\"Shape of 2D global max pooled random tensor: {global_max_pooled_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[0.49912712, 0.06667098, 0.06417489]], dtype=float32)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replicating global max pool 2D\n",
    "tf.reduce_mean(input_tensor,axis=[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random input tensor:\n",
      " [[[[ 0.6221494   0.39071774  0.572821  ]\n",
      "   [ 0.92682797  0.8460992   0.08634651]\n",
      "   [-0.39511812 -0.02012417  1.0490924 ]\n",
      "   [-0.3120731   0.41652173  0.8515276 ]]\n",
      "\n",
      "  [[-1.27271    -0.09542792 -0.16090107]\n",
      "   [-0.900317    0.9836345   0.94048667]\n",
      "   [ 1.4384675  -0.16801515 -0.43124875]\n",
      "   [-1.1060885   0.2186191   1.4111438 ]]\n",
      "\n",
      "  [[ 0.826967    1.1009964   0.02034463]\n",
      "   [-0.36579552  0.10911851 -0.22597931]\n",
      "   [ 0.3696448  -0.8651293   1.2661022 ]\n",
      "   [-0.49262673 -0.99944526 -0.08006851]]\n",
      "\n",
      "  [[ 1.7055075   0.10260425  1.1992584 ]\n",
      "   [-0.13475318 -0.4856558  -1.5140239 ]\n",
      "   [ 0.2532031   1.3699163   2.1776462 ]\n",
      "   [ 1.8093497  -1.3124373   0.39335868]]]]\n",
      "\n",
      "2D global max pooled random tensor:\n",
      " [[1.8093497 1.3699163 2.1776462]]\n",
      "\n",
      "Shape of input tensor: (1, 4, 4, 3)\n",
      "Shape of 2D global max pooled random tensor: (1, 3)\n"
     ]
    }
   ],
   "source": [
    "input_shape=(1,4,4,3)\n",
    "\n",
    "# create a random tensor\n",
    "input_tensor=tf.random.normal(input_shape)\n",
    "print(f\"Random input tensor:\\n {input_tensor}\\n\")\n",
    "\n",
    "# pass the random tensor through a global max pooling 2D layer\n",
    "global_max_pooled_tensor=tf.keras.layers.GlobalMaxPooling2D()(input_tensor)\n",
    "print(f\"2D global max pooled random tensor:\\n {global_max_pooled_tensor}\\n\")\n",
    "\n",
    "# check the shape\n",
    "print(f\"Shape of input tensor: {input_tensor.shape}\")\n",
    "print(f\"Shape of 2D global max pooled random tensor: {global_max_pooled_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[1.8093497, 1.3699163, 2.1776462]], dtype=float32)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replicating global max pool 2D\n",
    "tf.reduce_max(input_tensor,axis=[1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***-- CONTD IN NEXT NOTEBOOK --***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
