{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88781767",
   "metadata": {},
   "source": [
    "**01. Building the Bottleneck inverted residual block (BIR)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1091636",
   "metadata": {},
   "source": [
    "<img src = 'BIR.png' height = '300' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90acc290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DL needs\n",
    "import tensorflow as tf\n",
    "import keras as kr\n",
    "\n",
    "# Data needs\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Numerical computation needs\n",
    "import numpy as np\n",
    "\n",
    "# plotting needs\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n",
    "\n",
    "# ensuring reproducibility\n",
    "random_seed=42\n",
    "tf.random.set_seed(random_seed)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"keras\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d53aa5f",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "* Use `training` in the call() function of your layer if and only if using layers like `BatchNormalization()` or `Dropout()`, else omit using it, as the model doesn't train if `training` variable is used but not explicitly called/used within the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "48524873",
   "metadata": {},
   "outputs": [],
   "source": [
    "@kr.utils.register_keras_serializable(package='BottleNeckInverseResidualBlock')\n",
    "class BIR(kr.layers.Layer):\n",
    "    def __init__(self,input_channels,output_channels,expansion_factor,stride = 1,expansion_kernel_size = 1,depthwise_kernel_size = 3, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self._block_name = kwargs.get('name','BIR')\n",
    "        self.stride = stride\n",
    "        self.use_residual = (self.stride == 1 and input_channels == output_channels)\n",
    "        expanded_channels = input_channels * expansion_factor\n",
    "\n",
    "        # Expansion \n",
    "        self.expand_conv = tf.keras.layers.Conv2D(\n",
    "            filters = expanded_channels,\n",
    "            kernel_size = expansion_kernel_size,\n",
    "            padding = 'same',\n",
    "            use_bias = False,\n",
    "            name = f'{self._block_name}_expand'\n",
    "        )\n",
    "\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization(name = f'{self._block_name}_expand_BN')\n",
    "        self.relu1 = tf.keras.layers.ReLU(name=f'{self._block_name}_expand_relu')\n",
    "\n",
    "        # Depthwise convolution\n",
    "        self.depthwise_conv = tf.keras.layers.DepthwiseConv2D(\n",
    "            kernel_size = depthwise_kernel_size,\n",
    "            strides = self.stride,\n",
    "            padding = 'same',\n",
    "            use_bias = False,\n",
    "            name = f'{self._block_name}_depthwise'\n",
    "        )\n",
    "        self.bn2 = tf.keras.layers.BatchNormalization(name = f'{self._block_name}_depthwise_BN')\n",
    "        self.relu2 = tf.keras.layers.ReLU(name=f'{self._block_name}_depthwise_relu')\n",
    "\n",
    "\n",
    "        # Projection\n",
    "        self.project_conv = tf.keras.layers.Conv2D(\n",
    "            filters = output_channels,\n",
    "            kernel_size = 1,\n",
    "            padding = 'same',\n",
    "            use_bias = False,\n",
    "            name = f'{self._block_name}_project'\n",
    "        )\n",
    "        self.bn3 = tf.keras.layers.BatchNormalization(name = f'{self._block_name}_project_BN')\n",
    "\n",
    "\n",
    "        # Addition layer\n",
    "        self.add_layer = tf.keras.layers.Add(name = f'{self._block_name}_add')\n",
    "\n",
    "        ### putting together all layers:\n",
    "        \n",
    "\n",
    "    def call(self,inputs,training = False):\n",
    "        # expansion\n",
    "        x = self.expand_conv(inputs)\n",
    "        x = self.bn1(x,training = training)\n",
    "        x = self.relu1(x)\n",
    "\n",
    "        # depthwise convolution\n",
    "        x = self.depthwise_conv(x)\n",
    "        x = self.bn2(x,training = training)\n",
    "        x = self.relu2(x)\n",
    "\n",
    "        # projection\n",
    "        x = self.project_conv(x)\n",
    "        x = self.bn3(x,training = training)\n",
    "\n",
    "        # residual connection\n",
    "        if self.use_residual:\n",
    "            return self.add_layer([inputs,x])\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "775ebc21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_28\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_28\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BIR</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">712</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_39 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block_1 (\u001b[38;5;33mBIR\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │           \u001b[38;5;34m712\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">712</span> (2.78 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m712\u001b[0m (2.78 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">608</span> (2.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m608\u001b[0m (2.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">104</span> (416.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m104\u001b[0m (416.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(112,112,3))\n",
    "outputs = BIR(input_channels=3,output_channels=16,expansion_factor=6,name = \"block_1\")(inputs)\n",
    " \n",
    "model = tf.keras.models.Model(inputs = inputs, outputs= outputs)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9764fcbb",
   "metadata": {},
   "source": [
    "**02. Creating the encoder section**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da7a53b",
   "metadata": {},
   "source": [
    "<img src = 'QUICKSAL.png' width = '700'/>\n",
    "\n",
    "* Create 7 blocks of BIR with the following input/output shapes:\n",
    "  \n",
    "  |BIR block|Input shape|Stride|Output shape|Expansion factor (t) |n (repetitions)|\n",
    "  |---|---|---|---|---|---|\n",
    "  | B1 |112<sup>2</sup> x 32 |1|112<sup>2</sup> x 16 |1| 1 |\n",
    "  | B2 |112<sup>2</sup> x 16 |2|56<sup>2</sup> x 24 |6| 2 |\n",
    "  | B3 |56<sup>2</sup> x 24 |2|28<sup>2</sup> x 32 |6| 3 |\n",
    "  | B4 |28<sup>2</sup> x 32 |2|14<sup>2</sup> x 64 |6| 4 |\n",
    "  | B5 |14<sup>2</sup> x 64 |1|14<sup>2</sup> x 96 |6| 3 |\n",
    "  | B6 |14<sup>2</sup> x 96 |2|7<sup>2</sup> x 160 |6| 3 |\n",
    "  | B7 |7<sup>2</sup> x 160 |1|7<sup>2</sup> x 320 |6| 1 |\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "5da3a66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@kr.utils.register_keras_serializable(package='QUICKSAL_encoder')\n",
    "class QUICKSAL_encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.block_args = {\n",
    "            'block_1_1':{'input_channels':32,'output_channels': 16,'t':1,'stride':1},\n",
    "            'block_2_1':{'input_channels':16,'output_channels': 24,'t':6,'stride':1},\n",
    "            'block_2_2':{'input_channels':24,'output_channels': 24,'t':6,'stride':2},\n",
    "            'block_3_1':{'input_channels':24,'output_channels': 32,'t':6,'stride':1},\n",
    "            'block_3_2':{'input_channels':32,'output_channels': 32,'t':6,'stride':1},\n",
    "            'block_3_3':{'input_channels':32,'output_channels': 32,'t':6,'stride':2},\n",
    "            'block_4_1':{'input_channels':32,'output_channels': 64,'t':6,'stride':1},\n",
    "            'block_4_2':{'input_channels':64,'output_channels': 64,'t':6,'stride':1},\n",
    "            'block_4_3':{'input_channels':64,'output_channels': 64,'t':6,'stride':1},\n",
    "            'block_4_4':{'input_channels':64,'output_channels': 64,'t':6,'stride':2},\n",
    "            'block_5_1':{'input_channels':64,'output_channels': 96,'t':6,'stride':1},\n",
    "            'block_5_2':{'input_channels':96,'output_channels': 96,'t':6,'stride':1},\n",
    "            'block_5_3':{'input_channels':96,'output_channels': 96,'t':6,'stride':1},\n",
    "            'block_6_1':{'input_channels':96,'output_channels': 160,'t':6,'stride':1},\n",
    "            'block_6_2':{'input_channels':160,'output_channels': 160,'t':6,'stride':1},\n",
    "            'block_6_3':{'input_channels':160,'output_channels': 160,'t':6,'stride':2},\n",
    "            'block_7_1':{'input_channels':160,'output_channels': 320,'t':6,'stride':1},\n",
    "        }\n",
    "\n",
    "\n",
    "        # remaining layers have expansion kernal-size of 1x1\n",
    "        self._layers = [BIR(input_channels = block_params['input_channels'],\n",
    "                            output_channels = block_params['output_channels'],\n",
    "                            expansion_factor = block_params['t'],\n",
    "                            stride = block_params['stride'],\n",
    "                            name = block_name) for block_name,block_params in self.block_args.items()]\n",
    "        \n",
    "        self.all_outputs = {block_name:None for block_name in self.block_args.keys()}\n",
    "\n",
    "    def call(self,inputs):\n",
    "        x = self._layers[0](inputs)\n",
    "        self.all_outputs['block_1_1'] = x\n",
    "        for layer in self._layers[1:]:\n",
    "            x = layer(x)\n",
    "            self.all_outputs[layer.name] = x\n",
    "        needed_outputs_from = ['block_3_1','block_4_1','block_6_1','block_7_1']\n",
    "        return [self.all_outputs[block_name] for block_name in needed_outputs_from]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "b9268572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"encoder_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"encoder_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_74 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ QUICKSAL_ENCODER                │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>),   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,843,424</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">QUICKSAL_encoder</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>),    │               │\n",
       "│                                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>),   │               │\n",
       "│                                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>)]     │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_74 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ QUICKSAL_ENCODER                │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m32\u001b[0m),   │     \u001b[38;5;34m1,843,424\u001b[0m │\n",
       "│ (\u001b[38;5;33mQUICKSAL_encoder\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m),    │               │\n",
       "│                                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m160\u001b[0m),   │               │\n",
       "│                                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m320\u001b[0m)]     │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,843,424</span> (7.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,843,424\u001b[0m (7.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,811,872</span> (6.91 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,811,872\u001b[0m (6.91 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,552</span> (123.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m31,552\u001b[0m (123.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs = tf.keras.layers.Input(shape = (112,112,32))\n",
    "outputs = QUICKSAL_encoder(name = 'QUICKSAL_ENCODER')(inputs)\n",
    "encoder_model = tf.keras.models.Model(inputs = inputs, outputs = outputs,name = 'encoder_model')\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "1832c25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mbnet = tf.keras.applications.MobileNetV2(\n",
    "    include_top = False,\n",
    "    alpha = 1.0,\n",
    "    input_shape = (224,224,3),\n",
    "    weights = 'imagenet'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "c5596773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_layer_24 (None, 224, 224, 3)\n",
      "1 Conv1 (None, 112, 112, 32)\n",
      "2 bn_Conv1 (None, 112, 112, 32)\n",
      "3 Conv1_relu (None, 112, 112, 32)\n",
      "4 expanded_conv_depthwise (None, 112, 112, 32)\n",
      "5 expanded_conv_depthwise_BN (None, 112, 112, 32)\n",
      "6 expanded_conv_depthwise_relu (None, 112, 112, 32)\n",
      "7 expanded_conv_project (None, 112, 112, 16)\n",
      "8 expanded_conv_project_BN (None, 112, 112, 16)\n",
      "9 block_1_expand (None, 112, 112, 96)\n",
      "10 block_1_expand_BN (None, 112, 112, 96)\n",
      "11 block_1_expand_relu (None, 112, 112, 96)\n",
      "12 block_1_pad (None, 113, 113, 96)\n",
      "13 block_1_depthwise (None, 56, 56, 96)\n",
      "14 block_1_depthwise_BN (None, 56, 56, 96)\n",
      "15 block_1_depthwise_relu (None, 56, 56, 96)\n",
      "16 block_1_project (None, 56, 56, 24)\n",
      "17 block_1_project_BN (None, 56, 56, 24)\n",
      "18 block_2_expand (None, 56, 56, 144)\n",
      "19 block_2_expand_BN (None, 56, 56, 144)\n",
      "20 block_2_expand_relu (None, 56, 56, 144)\n",
      "21 block_2_depthwise (None, 56, 56, 144)\n",
      "22 block_2_depthwise_BN (None, 56, 56, 144)\n",
      "23 block_2_depthwise_relu (None, 56, 56, 144)\n",
      "24 block_2_project (None, 56, 56, 24)\n",
      "25 block_2_project_BN (None, 56, 56, 24)\n",
      "26 block_2_add (None, 56, 56, 24)\n",
      "27 block_3_expand (None, 56, 56, 144)\n",
      "28 block_3_expand_BN (None, 56, 56, 144)\n",
      "29 block_3_expand_relu (None, 56, 56, 144)\n",
      "30 block_3_pad (None, 57, 57, 144)\n",
      "31 block_3_depthwise (None, 28, 28, 144)\n",
      "32 block_3_depthwise_BN (None, 28, 28, 144)\n",
      "33 block_3_depthwise_relu (None, 28, 28, 144)\n",
      "34 block_3_project (None, 28, 28, 32)\n",
      "35 block_3_project_BN (None, 28, 28, 32)\n",
      "36 block_4_expand (None, 28, 28, 192)\n",
      "37 block_4_expand_BN (None, 28, 28, 192)\n",
      "38 block_4_expand_relu (None, 28, 28, 192)\n",
      "39 block_4_depthwise (None, 28, 28, 192)\n",
      "40 block_4_depthwise_BN (None, 28, 28, 192)\n",
      "41 block_4_depthwise_relu (None, 28, 28, 192)\n",
      "42 block_4_project (None, 28, 28, 32)\n",
      "43 block_4_project_BN (None, 28, 28, 32)\n",
      "44 block_4_add (None, 28, 28, 32)\n",
      "45 block_5_expand (None, 28, 28, 192)\n",
      "46 block_5_expand_BN (None, 28, 28, 192)\n",
      "47 block_5_expand_relu (None, 28, 28, 192)\n",
      "48 block_5_depthwise (None, 28, 28, 192)\n",
      "49 block_5_depthwise_BN (None, 28, 28, 192)\n",
      "50 block_5_depthwise_relu (None, 28, 28, 192)\n",
      "51 block_5_project (None, 28, 28, 32)\n",
      "52 block_5_project_BN (None, 28, 28, 32)\n",
      "53 block_5_add (None, 28, 28, 32)\n",
      "54 block_6_expand (None, 28, 28, 192)\n",
      "55 block_6_expand_BN (None, 28, 28, 192)\n",
      "56 block_6_expand_relu (None, 28, 28, 192)\n",
      "57 block_6_pad (None, 29, 29, 192)\n",
      "58 block_6_depthwise (None, 14, 14, 192)\n",
      "59 block_6_depthwise_BN (None, 14, 14, 192)\n",
      "60 block_6_depthwise_relu (None, 14, 14, 192)\n",
      "61 block_6_project (None, 14, 14, 64)\n",
      "62 block_6_project_BN (None, 14, 14, 64)\n",
      "63 block_7_expand (None, 14, 14, 384)\n",
      "64 block_7_expand_BN (None, 14, 14, 384)\n",
      "65 block_7_expand_relu (None, 14, 14, 384)\n",
      "66 block_7_depthwise (None, 14, 14, 384)\n",
      "67 block_7_depthwise_BN (None, 14, 14, 384)\n",
      "68 block_7_depthwise_relu (None, 14, 14, 384)\n",
      "69 block_7_project (None, 14, 14, 64)\n",
      "70 block_7_project_BN (None, 14, 14, 64)\n",
      "71 block_7_add (None, 14, 14, 64)\n",
      "72 block_8_expand (None, 14, 14, 384)\n",
      "73 block_8_expand_BN (None, 14, 14, 384)\n",
      "74 block_8_expand_relu (None, 14, 14, 384)\n",
      "75 block_8_depthwise (None, 14, 14, 384)\n",
      "76 block_8_depthwise_BN (None, 14, 14, 384)\n",
      "77 block_8_depthwise_relu (None, 14, 14, 384)\n",
      "78 block_8_project (None, 14, 14, 64)\n",
      "79 block_8_project_BN (None, 14, 14, 64)\n",
      "80 block_8_add (None, 14, 14, 64)\n",
      "81 block_9_expand (None, 14, 14, 384)\n",
      "82 block_9_expand_BN (None, 14, 14, 384)\n",
      "83 block_9_expand_relu (None, 14, 14, 384)\n",
      "84 block_9_depthwise (None, 14, 14, 384)\n",
      "85 block_9_depthwise_BN (None, 14, 14, 384)\n",
      "86 block_9_depthwise_relu (None, 14, 14, 384)\n",
      "87 block_9_project (None, 14, 14, 64)\n",
      "88 block_9_project_BN (None, 14, 14, 64)\n",
      "89 block_9_add (None, 14, 14, 64)\n",
      "90 block_10_expand (None, 14, 14, 384)\n",
      "91 block_10_expand_BN (None, 14, 14, 384)\n",
      "92 block_10_expand_relu (None, 14, 14, 384)\n",
      "93 block_10_depthwise (None, 14, 14, 384)\n",
      "94 block_10_depthwise_BN (None, 14, 14, 384)\n",
      "95 block_10_depthwise_relu (None, 14, 14, 384)\n",
      "96 block_10_project (None, 14, 14, 96)\n",
      "97 block_10_project_BN (None, 14, 14, 96)\n",
      "98 block_11_expand (None, 14, 14, 576)\n",
      "99 block_11_expand_BN (None, 14, 14, 576)\n",
      "100 block_11_expand_relu (None, 14, 14, 576)\n",
      "101 block_11_depthwise (None, 14, 14, 576)\n",
      "102 block_11_depthwise_BN (None, 14, 14, 576)\n",
      "103 block_11_depthwise_relu (None, 14, 14, 576)\n",
      "104 block_11_project (None, 14, 14, 96)\n",
      "105 block_11_project_BN (None, 14, 14, 96)\n",
      "106 block_11_add (None, 14, 14, 96)\n",
      "107 block_12_expand (None, 14, 14, 576)\n",
      "108 block_12_expand_BN (None, 14, 14, 576)\n",
      "109 block_12_expand_relu (None, 14, 14, 576)\n",
      "110 block_12_depthwise (None, 14, 14, 576)\n",
      "111 block_12_depthwise_BN (None, 14, 14, 576)\n",
      "112 block_12_depthwise_relu (None, 14, 14, 576)\n",
      "113 block_12_project (None, 14, 14, 96)\n",
      "114 block_12_project_BN (None, 14, 14, 96)\n",
      "115 block_12_add (None, 14, 14, 96)\n",
      "116 block_13_expand (None, 14, 14, 576)\n",
      "117 block_13_expand_BN (None, 14, 14, 576)\n",
      "118 block_13_expand_relu (None, 14, 14, 576)\n",
      "119 block_13_pad (None, 15, 15, 576)\n",
      "120 block_13_depthwise (None, 7, 7, 576)\n",
      "121 block_13_depthwise_BN (None, 7, 7, 576)\n",
      "122 block_13_depthwise_relu (None, 7, 7, 576)\n",
      "123 block_13_project (None, 7, 7, 160)\n",
      "124 block_13_project_BN (None, 7, 7, 160)\n",
      "125 block_14_expand (None, 7, 7, 960)\n",
      "126 block_14_expand_BN (None, 7, 7, 960)\n",
      "127 block_14_expand_relu (None, 7, 7, 960)\n",
      "128 block_14_depthwise (None, 7, 7, 960)\n",
      "129 block_14_depthwise_BN (None, 7, 7, 960)\n",
      "130 block_14_depthwise_relu (None, 7, 7, 960)\n",
      "131 block_14_project (None, 7, 7, 160)\n",
      "132 block_14_project_BN (None, 7, 7, 160)\n",
      "133 block_14_add (None, 7, 7, 160)\n",
      "134 block_15_expand (None, 7, 7, 960)\n",
      "135 block_15_expand_BN (None, 7, 7, 960)\n",
      "136 block_15_expand_relu (None, 7, 7, 960)\n",
      "137 block_15_depthwise (None, 7, 7, 960)\n",
      "138 block_15_depthwise_BN (None, 7, 7, 960)\n",
      "139 block_15_depthwise_relu (None, 7, 7, 960)\n",
      "140 block_15_project (None, 7, 7, 160)\n",
      "141 block_15_project_BN (None, 7, 7, 160)\n",
      "142 block_15_add (None, 7, 7, 160)\n",
      "143 block_16_expand (None, 7, 7, 960)\n",
      "144 block_16_expand_BN (None, 7, 7, 960)\n",
      "145 block_16_expand_relu (None, 7, 7, 960)\n",
      "146 block_16_depthwise (None, 7, 7, 960)\n",
      "147 block_16_depthwise_BN (None, 7, 7, 960)\n",
      "148 block_16_depthwise_relu (None, 7, 7, 960)\n",
      "149 block_16_project (None, 7, 7, 320)\n",
      "150 block_16_project_BN (None, 7, 7, 320)\n",
      "151 Conv_1 (None, 7, 7, 1280)\n",
      "152 Conv_1_bn (None, 7, 7, 1280)\n",
      "153 out_relu (None, 7, 7, 1280)\n"
     ]
    }
   ],
   "source": [
    "for i,layer in enumerate(mbnet.layers):\n",
    "    print(i,layer.name,layer.output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3536fd9d",
   "metadata": {},
   "source": [
    "**03. Adding pre-trained weights of MobileNet-v2 (imagenet) to encoder layer, and setting `trainable=False` except the expand layer in the first block** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3cb473",
   "metadata": {},
   "source": [
    "  |BIR block|MobileNet-V2 model layer match-indices/model-names|\n",
    "  |---|---|\n",
    "  | B1 |2-8|\n",
    "  | B2 |block_1,block_2|\n",
    "  | B3 |block_3,block_4,block_5|\n",
    "  | B4 |block_6,block_7,block_8,block_9|\n",
    "  | B5 |block_10,block_11,block_12|\n",
    "  | B6 |block_13,block_14,block_15|\n",
    "  | B7 |block_16|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "840a3052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_encoder_weights(enc,mbnet):\n",
    "    ### For block 1: \n",
    "    ### first line is commented because \n",
    "    # enc._layers[0]._layers[0].set_weights(mbnet.layers[1].get_weights()) \n",
    "    enc._layers[0]._layers[1].set_weights(mbnet.layers[2].get_weights())\n",
    "    enc._layers[0]._layers[3].set_weights(mbnet.layers[4].get_weights())\n",
    "    enc._layers[0]._layers[4].set_weights(mbnet.layers[5].get_weights())\n",
    "    enc._layers[0]._layers[6].set_weights(mbnet.layers[7].get_weights())\n",
    "    enc._layers[0]._layers[7].set_weights(mbnet.layers[8].get_weights())  \n",
    "\n",
    "    # For block 2 to 7\n",
    "    i=1\n",
    "    # setting the weights\n",
    "    for block in enc._layers[1:]:\n",
    "        for layer in block._layers:\n",
    "            # setting expand layer\n",
    "            if layer.name[10:] == 'expand':\n",
    "                layer.set_weights(mbnet.get_layer(f'block_{i}_expand').get_weights())\n",
    "            elif layer.name[10:] == 'expand_BN':\n",
    "                layer.set_weights(mbnet.get_layer(f'block_{i}_expand_BN').get_weights())\n",
    "            elif layer.name[10:] == 'depthwise':\n",
    "                layer.set_weights(mbnet.get_layer(f'block_{i}_depthwise').get_weights())\n",
    "            elif layer.name[10:] == 'depthwise_BN':\n",
    "                layer.set_weights(mbnet.get_layer(f'block_{i}_depthwise_BN').get_weights())\n",
    "            elif layer.name[10:] == 'project':\n",
    "                layer.set_weights(mbnet.get_layer(f'block_{i}_project').get_weights())\n",
    "            elif layer.name[10:] == 'project_BN':\n",
    "                layer.set_weights(mbnet.get_layer(f'block_{i}_project_BN').get_weights())\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "885744d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = QUICKSAL_encoder()\n",
    "_ = enc(tf.keras.layers.Input((112,112,32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec65dc7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-04-26 00:50:24--  http://mftp.mmcheng.net/Data/MSRA10K_Imgs_GT.zip\n",
      "Resolving mftp.mmcheng.net (mftp.mmcheng.net)... 108.179.200.15\n",
      "Connecting to mftp.mmcheng.net (mftp.mmcheng.net)|108.179.200.15|:80... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://mftp.mmcheng.net/Data/MSRA10K_Imgs_GT.zip [following]\n",
      "--2025-04-26 00:50:25--  https://mftp.mmcheng.net/Data/MSRA10K_Imgs_GT.zip\n",
      "Connecting to mftp.mmcheng.net (mftp.mmcheng.net)|108.179.200.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 205213299 (196M) [application/zip]\n",
      "Saving to: ‘MSRA10K_Imgs_GT.zip’\n",
      "\n",
      "MSRA10K_Imgs_GT.zip 100%[===================>] 195.71M  7.69MB/s    in 42s     \n",
      "\n",
      "2025-04-26 00:51:09 (4.62 MB/s) - ‘MSRA10K_Imgs_GT.zip’ saved [205213299/205213299]\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "5625b9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_encoder_weights(enc,mbnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "90447ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for block in enc._layers[:]:\n",
    "    block.trainable = False\n",
    "\n",
    "enc._layers[0]._layers[0].trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "27bb3680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block_1_1\n",
      "block_1_1_expand True\n",
      "block_1_1_expand_BN False\n",
      "block_1_1_expand_relu False\n",
      "block_1_1_depthwise False\n",
      "block_1_1_depthwise_BN False\n",
      "block_1_1_depthwise_relu False\n",
      "block_1_1_project False\n",
      "block_1_1_project_BN False\n",
      "block_1_1_add False\n",
      "block_2_1\n",
      "block_2_1_expand False\n",
      "block_2_1_expand_BN False\n",
      "block_2_1_expand_relu False\n",
      "block_2_1_depthwise False\n",
      "block_2_1_depthwise_BN False\n",
      "block_2_1_depthwise_relu False\n",
      "block_2_1_project False\n",
      "block_2_1_project_BN False\n",
      "block_2_1_add False\n",
      "block_2_2\n",
      "block_2_2_expand False\n",
      "block_2_2_expand_BN False\n",
      "block_2_2_expand_relu False\n",
      "block_2_2_depthwise False\n",
      "block_2_2_depthwise_BN False\n",
      "block_2_2_depthwise_relu False\n",
      "block_2_2_project False\n",
      "block_2_2_project_BN False\n",
      "block_2_2_add False\n",
      "block_3_1\n",
      "block_3_1_expand False\n",
      "block_3_1_expand_BN False\n",
      "block_3_1_expand_relu False\n",
      "block_3_1_depthwise False\n",
      "block_3_1_depthwise_BN False\n",
      "block_3_1_depthwise_relu False\n",
      "block_3_1_project False\n",
      "block_3_1_project_BN False\n",
      "block_3_1_add False\n",
      "block_3_2\n",
      "block_3_2_expand False\n",
      "block_3_2_expand_BN False\n",
      "block_3_2_expand_relu False\n",
      "block_3_2_depthwise False\n",
      "block_3_2_depthwise_BN False\n",
      "block_3_2_depthwise_relu False\n",
      "block_3_2_project False\n",
      "block_3_2_project_BN False\n",
      "block_3_2_add False\n",
      "block_3_3\n",
      "block_3_3_expand False\n",
      "block_3_3_expand_BN False\n",
      "block_3_3_expand_relu False\n",
      "block_3_3_depthwise False\n",
      "block_3_3_depthwise_BN False\n",
      "block_3_3_depthwise_relu False\n",
      "block_3_3_project False\n",
      "block_3_3_project_BN False\n",
      "block_3_3_add False\n",
      "block_4_1\n",
      "block_4_1_expand False\n",
      "block_4_1_expand_BN False\n",
      "block_4_1_expand_relu False\n",
      "block_4_1_depthwise False\n",
      "block_4_1_depthwise_BN False\n",
      "block_4_1_depthwise_relu False\n",
      "block_4_1_project False\n",
      "block_4_1_project_BN False\n",
      "block_4_1_add False\n",
      "block_4_2\n",
      "block_4_2_expand False\n",
      "block_4_2_expand_BN False\n",
      "block_4_2_expand_relu False\n",
      "block_4_2_depthwise False\n",
      "block_4_2_depthwise_BN False\n",
      "block_4_2_depthwise_relu False\n",
      "block_4_2_project False\n",
      "block_4_2_project_BN False\n",
      "block_4_2_add False\n",
      "block_4_3\n",
      "block_4_3_expand False\n",
      "block_4_3_expand_BN False\n",
      "block_4_3_expand_relu False\n",
      "block_4_3_depthwise False\n",
      "block_4_3_depthwise_BN False\n",
      "block_4_3_depthwise_relu False\n",
      "block_4_3_project False\n",
      "block_4_3_project_BN False\n",
      "block_4_3_add False\n",
      "block_4_4\n",
      "block_4_4_expand False\n",
      "block_4_4_expand_BN False\n",
      "block_4_4_expand_relu False\n",
      "block_4_4_depthwise False\n",
      "block_4_4_depthwise_BN False\n",
      "block_4_4_depthwise_relu False\n",
      "block_4_4_project False\n",
      "block_4_4_project_BN False\n",
      "block_4_4_add False\n",
      "block_5_1\n",
      "block_5_1_expand False\n",
      "block_5_1_expand_BN False\n",
      "block_5_1_expand_relu False\n",
      "block_5_1_depthwise False\n",
      "block_5_1_depthwise_BN False\n",
      "block_5_1_depthwise_relu False\n",
      "block_5_1_project False\n",
      "block_5_1_project_BN False\n",
      "block_5_1_add False\n",
      "block_5_2\n",
      "block_5_2_expand False\n",
      "block_5_2_expand_BN False\n",
      "block_5_2_expand_relu False\n",
      "block_5_2_depthwise False\n",
      "block_5_2_depthwise_BN False\n",
      "block_5_2_depthwise_relu False\n",
      "block_5_2_project False\n",
      "block_5_2_project_BN False\n",
      "block_5_2_add False\n",
      "block_5_3\n",
      "block_5_3_expand False\n",
      "block_5_3_expand_BN False\n",
      "block_5_3_expand_relu False\n",
      "block_5_3_depthwise False\n",
      "block_5_3_depthwise_BN False\n",
      "block_5_3_depthwise_relu False\n",
      "block_5_3_project False\n",
      "block_5_3_project_BN False\n",
      "block_5_3_add False\n",
      "block_6_1\n",
      "block_6_1_expand False\n",
      "block_6_1_expand_BN False\n",
      "block_6_1_expand_relu False\n",
      "block_6_1_depthwise False\n",
      "block_6_1_depthwise_BN False\n",
      "block_6_1_depthwise_relu False\n",
      "block_6_1_project False\n",
      "block_6_1_project_BN False\n",
      "block_6_1_add False\n",
      "block_6_2\n",
      "block_6_2_expand False\n",
      "block_6_2_expand_BN False\n",
      "block_6_2_expand_relu False\n",
      "block_6_2_depthwise False\n",
      "block_6_2_depthwise_BN False\n",
      "block_6_2_depthwise_relu False\n",
      "block_6_2_project False\n",
      "block_6_2_project_BN False\n",
      "block_6_2_add False\n",
      "block_6_3\n",
      "block_6_3_expand False\n",
      "block_6_3_expand_BN False\n",
      "block_6_3_expand_relu False\n",
      "block_6_3_depthwise False\n",
      "block_6_3_depthwise_BN False\n",
      "block_6_3_depthwise_relu False\n",
      "block_6_3_project False\n",
      "block_6_3_project_BN False\n",
      "block_6_3_add False\n",
      "block_7_1\n",
      "block_7_1_expand False\n",
      "block_7_1_expand_BN False\n",
      "block_7_1_expand_relu False\n",
      "block_7_1_depthwise False\n",
      "block_7_1_depthwise_BN False\n",
      "block_7_1_depthwise_relu False\n",
      "block_7_1_project False\n",
      "block_7_1_project_BN False\n",
      "block_7_1_add False\n"
     ]
    }
   ],
   "source": [
    "for block in enc._layers:\n",
    "    print(block.name)\n",
    "    for layer in block._layers:\n",
    "        print(layer.name,layer.trainable)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
