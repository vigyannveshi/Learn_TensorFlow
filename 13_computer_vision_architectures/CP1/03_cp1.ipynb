{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88781767",
   "metadata": {},
   "source": [
    "**06. Putting all blocks together to build QUICKSAL**\n",
    "<br>\n",
    "<img src=\"QUICKSAL.png\" width = \"700\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90acc290",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-30 13:27:13.988129: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# DL needs\n",
    "import tensorflow as tf\n",
    "import keras as kr\n",
    "\n",
    "# Data needs\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Numerical computation needs\n",
    "import numpy as np\n",
    "\n",
    "# plotting needs\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n",
    "\n",
    "# ensuring reproducibility\n",
    "random_seed=42\n",
    "tf.random.set_seed(random_seed)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"keras\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82923793",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "* We have set the dtype of `tf.keras.layers.ReLU()` to `tf.float32`\n",
    "* We have set the dtype of `tf.keras.layers.Activation('softmax')` to `tf.float32`\n",
    "* This is done so that during mixed precision training, the precision of activation function output is not lost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420ebb17",
   "metadata": {},
   "source": [
    "**Bottleneck Inverted Residual Block class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aacbbb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bottleneck Inverted Residual Block class\n",
    "@kr.utils.register_keras_serializable(package='BottleNeckInverseResidualBlock')\n",
    "class BIR(kr.layers.Layer):\n",
    "    def __init__(self,input_channels,output_channels,expansion_factor,stride = 1,expansion_kernel_size = 1,depthwise_kernel_size = 3, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self._block_name = kwargs.get('name','BIR')\n",
    "        self.stride = stride\n",
    "        self.use_residual = (self.stride == 1 and input_channels == output_channels)\n",
    "        expanded_channels = input_channels * expansion_factor\n",
    "\n",
    "        # Expansion \n",
    "        self.expand_conv = tf.keras.layers.Conv2D(\n",
    "            filters = expanded_channels,\n",
    "            kernel_size = expansion_kernel_size,\n",
    "            padding = 'same',\n",
    "            use_bias = False,\n",
    "            name = f'{self._block_name}_expand'\n",
    "        )\n",
    "\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization(name = f'{self._block_name}_expand_BN')\n",
    "        self.relu1 = tf.keras.layers.Activation('relu',name=f'{self._block_name}_expand_relu',dtype = tf.float32)\n",
    "\n",
    "        # Depthwise convolution\n",
    "        self.depthwise_conv = tf.keras.layers.DepthwiseConv2D(\n",
    "            kernel_size = depthwise_kernel_size,\n",
    "            strides = self.stride,\n",
    "            padding = 'same',\n",
    "            use_bias = False,\n",
    "            name = f'{self._block_name}_depthwise'\n",
    "        )\n",
    "        self.bn2 = tf.keras.layers.BatchNormalization(name = f'{self._block_name}_depthwise_BN')\n",
    "        self.relu2 = tf.keras.layers.Activation('relu',name=f'{self._block_name}_depthwise_relu',dtype = tf.float32)\n",
    "\n",
    "\n",
    "        # Projection\n",
    "        self.project_conv = tf.keras.layers.Conv2D(\n",
    "            filters = output_channels,\n",
    "            kernel_size = 1,\n",
    "            padding = 'same',\n",
    "            use_bias = False,\n",
    "            name = f'{self._block_name}_project'\n",
    "        )\n",
    "        self.bn3 = tf.keras.layers.BatchNormalization(name = f'{self._block_name}_project_BN')\n",
    "\n",
    "\n",
    "        # Addition layer\n",
    "        self.add_layer = tf.keras.layers.Add(name = f'{self._block_name}_add')\n",
    "        \n",
    "\n",
    "    def call(self,inputs,training = False):\n",
    "        # expansion\n",
    "        x = self.expand_conv(inputs)\n",
    "        x = self.bn1(x,training = training)\n",
    "        x = self.relu1(x)\n",
    "\n",
    "        # depthwise convolution\n",
    "        x = self.depthwise_conv(x)\n",
    "        x = self.bn2(x,training = training)\n",
    "        x = self.relu2(x)\n",
    "\n",
    "        # projection\n",
    "        x = self.project_conv(x)\n",
    "        x = self.bn3(x,training = training)\n",
    "\n",
    "        # residual connection\n",
    "        if self.use_residual:\n",
    "            return self.add_layer([inputs,x])\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1c1c55",
   "metadata": {},
   "source": [
    "**Encoder-section implementation class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7889cf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder-section implementation class\n",
    "@kr.utils.register_keras_serializable(package='QUICKSAL_encoder')\n",
    "class QUICKSAL_encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.block_args = {\n",
    "            'block_1_1':{'input_channels':32,'output_channels': 16,'t':1,'stride':1},\n",
    "            'block_2_1':{'input_channels':16,'output_channels': 24,'t':6,'stride':1},\n",
    "            'block_2_2':{'input_channels':24,'output_channels': 24,'t':6,'stride':2},\n",
    "            'block_3_1':{'input_channels':24,'output_channels': 32,'t':6,'stride':1},\n",
    "            'block_3_2':{'input_channels':32,'output_channels': 32,'t':6,'stride':1},\n",
    "            'block_3_3':{'input_channels':32,'output_channels': 32,'t':6,'stride':2},\n",
    "            'block_4_1':{'input_channels':32,'output_channels': 64,'t':6,'stride':1},\n",
    "            'block_4_2':{'input_channels':64,'output_channels': 64,'t':6,'stride':1},\n",
    "            'block_4_3':{'input_channels':64,'output_channels': 64,'t':6,'stride':1},\n",
    "            'block_4_4':{'input_channels':64,'output_channels': 64,'t':6,'stride':2},\n",
    "            'block_5_1':{'input_channels':64,'output_channels': 96,'t':6,'stride':1},\n",
    "            'block_5_2':{'input_channels':96,'output_channels': 96,'t':6,'stride':1},\n",
    "            'block_5_3':{'input_channels':96,'output_channels': 96,'t':6,'stride':1},\n",
    "            'block_6_1':{'input_channels':96,'output_channels': 160,'t':6,'stride':1},\n",
    "            'block_6_2':{'input_channels':160,'output_channels': 160,'t':6,'stride':1},\n",
    "            'block_6_3':{'input_channels':160,'output_channels': 160,'t':6,'stride':2},\n",
    "            'block_7_1':{'input_channels':160,'output_channels': 320,'t':6,'stride':1},\n",
    "        }\n",
    "\n",
    "\n",
    "        # remaining layers have expansion kernal-size of 1x1\n",
    "        self._layers = [BIR(input_channels = block_params['input_channels'],\n",
    "                            output_channels = block_params['output_channels'],\n",
    "                            expansion_factor = block_params['t'],\n",
    "                            stride = block_params['stride'],\n",
    "                            name = block_name) for block_name,block_params in self.block_args.items()]\n",
    "        \n",
    "        self.all_outputs = {block_name:None for block_name in self.block_args.keys()}\n",
    "\n",
    "    def call(self,inputs):\n",
    "        x = self._layers[0](inputs)\n",
    "        self.all_outputs['block_1_1'] = x\n",
    "        for layer in self._layers[1:]:\n",
    "            x = layer(x)\n",
    "            self.all_outputs[layer.name] = x\n",
    "        needed_outputs_from = ['block_2_2','block_3_3','block_5_3','block_7_1']\n",
    "        return [self.all_outputs[block_name] for block_name in needed_outputs_from]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "383795de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_encoder_weights(enc,mbnet):\n",
    "    ### For block 1: \n",
    "    ### first line is commented because \n",
    "    # enc._layers[0]._layers[0].set_weights(mbnet.layers[1].get_weights()) \n",
    "    enc._layers[0]._layers[1].set_weights(mbnet.layers[2].get_weights())\n",
    "    enc._layers[0]._layers[3].set_weights(mbnet.layers[4].get_weights())\n",
    "    enc._layers[0]._layers[4].set_weights(mbnet.layers[5].get_weights())\n",
    "    enc._layers[0]._layers[6].set_weights(mbnet.layers[7].get_weights())\n",
    "    enc._layers[0]._layers[7].set_weights(mbnet.layers[8].get_weights())  \n",
    "\n",
    "    # For block 2 to 7\n",
    "    i=1\n",
    "    # setting the weights\n",
    "    for block in enc._layers[1:]:\n",
    "        for layer in block._layers:\n",
    "            # setting expand layer\n",
    "            if layer.name[10:] == 'expand':\n",
    "                layer.set_weights(mbnet.get_layer(f'block_{i}_expand').get_weights())\n",
    "            elif layer.name[10:] == 'expand_BN':\n",
    "                layer.set_weights(mbnet.get_layer(f'block_{i}_expand_BN').get_weights())\n",
    "            elif layer.name[10:] == 'depthwise':\n",
    "                layer.set_weights(mbnet.get_layer(f'block_{i}_depthwise').get_weights())\n",
    "            elif layer.name[10:] == 'depthwise_BN':\n",
    "                layer.set_weights(mbnet.get_layer(f'block_{i}_depthwise_BN').get_weights())\n",
    "            elif layer.name[10:] == 'project':\n",
    "                layer.set_weights(mbnet.get_layer(f'block_{i}_project').get_weights())\n",
    "            elif layer.name[10:] == 'project_BN':\n",
    "                layer.set_weights(mbnet.get_layer(f'block_{i}_project_BN').get_weights())\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04771665",
   "metadata": {},
   "source": [
    "**Inception Block class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48524873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inception Block class\n",
    "\n",
    "@kr.utils.register_keras_serializable(package='InceptionBlock')\n",
    "class InceptionBlock(kr.layers.Layer):\n",
    "    def __init__(self,input_channels,output_channels,expansion_factor,conv_stride = 1,expansion_kernel_size = 1,depthwise_width = 3, depthwise_kernel_sizes = [3,3,3],depthwise_dilation_rates = [1,2,3], transpose_kernel_size=3,transpose_stride=2, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self._block_name = kwargs.get('name','InceptionBlock')\n",
    "        self.conv_stride = conv_stride\n",
    "        self.transpose_stride = transpose_stride\n",
    "\n",
    "        expanded_channels = input_channels * expansion_factor\n",
    "        self.depthwise_width = depthwise_width\n",
    "\n",
    "        # Expansion \n",
    "        self.expand_conv = tf.keras.layers.Conv2D(\n",
    "            filters = expanded_channels,\n",
    "            kernel_size = expansion_kernel_size,\n",
    "            padding = 'same',\n",
    "            use_bias = False,\n",
    "            name = f'{self._block_name}_expand'\n",
    "        )\n",
    "\n",
    "        self.bn_e = tf.keras.layers.BatchNormalization(name = f'{self._block_name}_expand_BN')\n",
    "        self.relu_e = tf.keras.layers.Activation('relu',name=f'{self._block_name}_expand_relu',dtype = tf.float32)\n",
    "\n",
    "        # Depthwise convolution x 3\n",
    "        self.depthwise = [\n",
    "            [tf.keras.layers.DepthwiseConv2D(\n",
    "                kernel_size = depthwise_kernel_sizes[0],\n",
    "                strides = self.conv_stride,\n",
    "                padding = 'same',\n",
    "                use_bias = False,\n",
    "                name = f'{self._block_name}_depthwise_{i+1}',\n",
    "                dilation_rate = depthwise_dilation_rates[0]\n",
    "            ),\n",
    "            tf.keras.layers.BatchNormalization(name = f'{self._block_name}_depthwise_BN_{i+1}')\n",
    "            ]\n",
    "            for i in range(depthwise_width)\n",
    "        ]\n",
    "\n",
    "        # Concat layer\n",
    "        self.concat = tf.keras.layers.Concatenate(name =f'{self._block_name}_concat' )\n",
    "        \n",
    "        # Concat relu\n",
    "        self.relu_concat = tf.keras.layers.Activation('relu',name=f'{self._block_name}_concat_relu',)\n",
    "\n",
    "        # Projection\n",
    "        self.project_conv = tf.keras.layers.Conv2D(\n",
    "            filters = output_channels,\n",
    "            kernel_size = 1,\n",
    "            padding = 'same',\n",
    "            use_bias = False,\n",
    "            name = f'{self._block_name}_project'\n",
    "        )\n",
    "        self.bn_p = tf.keras.layers.BatchNormalization(name = f'{self._block_name}_project_BN')\n",
    "\n",
    "        # Transpose Convolution layer \n",
    "        self.transpose_conv = tf.keras.layers.Conv2DTranspose(\n",
    "            filters = output_channels,\n",
    "            kernel_size = transpose_kernel_size,\n",
    "            strides = self.transpose_stride,\n",
    "            padding = 'same',\n",
    "            use_bias = False,\n",
    "            name = f'{self._block_name}_transpose_conv'\n",
    "        )\n",
    "\n",
    "        self.bn_tc = tf.keras.layers.BatchNormalization(name = f'{self._block_name}_transpose_conv_BN')\n",
    "\n",
    "\n",
    "    def call(self,inputs,training = False):\n",
    "        # expansion\n",
    "        x = self.expand_conv(inputs)\n",
    "        x = self.bn_e(x,training = training)\n",
    "        x = self.relu_e(x)\n",
    "\n",
    "        # depthwise convolution\n",
    "        depthwise_out = []\n",
    "        for depthwise_layer in self.depthwise:\n",
    "            # BatchNorm(DepthwiseConv(x))\n",
    "            depthwise_out.append(depthwise_layer[1](depthwise_layer[0](x),training = training))\n",
    "        \n",
    "        depthwise_out+=[x]\n",
    "        \n",
    "        # concatenation\n",
    "        x = self.concat(depthwise_out)\n",
    "        x = self.relu_concat(x)\n",
    "\n",
    "        # projection\n",
    "        x = self.project_conv(x)\n",
    "        x = self.bn_p(x,training = training)\n",
    "\n",
    "        # transpose convolution\n",
    "        x = self.transpose_conv(x)\n",
    "        x = self.bn_tc(x,training = training)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41656bb6",
   "metadata": {},
   "source": [
    "**Decoder Section implementation class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f12598fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder creation\n",
    "\n",
    "@kr.utils.register_keras_serializable(package='QUICKSAL_decoder')\n",
    "class QUICKSAL_decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # inception blocks\n",
    "        self.inc1 = InceptionBlock(input_channels=32,output_channels=16,expansion_factor=6,conv_stride=1, depthwise_width=4,depthwise_kernel_sizes=[1,3,5,7], depthwise_dilation_rates=[1,1,1,1],transpose_kernel_size=3,transpose_stride=2,name='inception_1')\n",
    "\n",
    "        self.inc2 = InceptionBlock(input_channels=48,output_channels=16,expansion_factor=6,conv_stride=1, depthwise_width=4,depthwise_kernel_sizes=[1,3,5,7], depthwise_dilation_rates=[1,1,1,1],transpose_kernel_size=3,transpose_stride=2,name='inception_2')\n",
    "\n",
    "        self.inc3 = InceptionBlock(input_channels=64,output_channels=24,expansion_factor=6,conv_stride=1, depthwise_width=3,depthwise_kernel_sizes=[1,3,5], depthwise_dilation_rates=[1,1,1],transpose_kernel_size=3,transpose_stride=2,name='inception_3')\n",
    "\n",
    "        self.inc4 = InceptionBlock(input_channels=192,output_channels=32,expansion_factor=6,conv_stride=1, depthwise_width=3,depthwise_kernel_sizes=[1,3,5], depthwise_dilation_rates=[1,1,1],transpose_kernel_size=3,transpose_stride=2,name='inception_4')\n",
    "\n",
    "        self.inc5 = InceptionBlock(input_channels=320,output_channels=96,expansion_factor=6,conv_stride=1, depthwise_width=2,depthwise_kernel_sizes=[1,3], depthwise_dilation_rates=[1,1],transpose_kernel_size=3,transpose_stride=2,name='inception_5')\n",
    "\n",
    "        # concat blocks\n",
    "        self.concat_1 = tf.keras.layers.Concatenate(name = 'dec_concat_1')\n",
    "        self.concat_2 = tf.keras.layers.Concatenate(name = 'dec_concat_2')\n",
    "        self.concat_3 = tf.keras.layers.Concatenate(name = 'dec_concat_3')\n",
    "        self.concat_4 = tf.keras.layers.Concatenate(name = 'dec_concat_4')\n",
    "    \n",
    "    def call(self,inputs):\n",
    "        conv1_out,bir2_out,bir3_out,bir5_out,bir7_out = inputs\n",
    "        inc5_out = self.inc5(bir7_out)\n",
    "\n",
    "        inc4_in = self.concat_4([bir5_out,inc5_out])\n",
    "        inc4_out = self.inc4(inc4_in)\n",
    "\n",
    "        inc3_in = self.concat_3([bir3_out,inc4_out])\n",
    "        inc3_out = self.inc3(inc3_in)\n",
    "        \n",
    "        inc2_in = self.concat_2([bir2_out,inc3_out])\n",
    "        inc2_out = self.inc2(inc2_in)\n",
    "\n",
    "        inc1_in = self.concat_1([conv1_out,inc2_out])\n",
    "        inc1_out = self.inc1(inc1_in)\n",
    "\n",
    "        return inc1_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d9336e",
   "metadata": {},
   "source": [
    "**Loading mobilenet-v2 model from tensorflow to use its pretrained-weights(imagenet)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "775ebc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "mbnet = tf.keras.applications.MobileNetV2(\n",
    "    include_top = False,\n",
    "    alpha = 1.0,\n",
    "    input_shape = (224,224,3),\n",
    "    weights = 'imagenet'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a25c09d",
   "metadata": {},
   "source": [
    "**Building the model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98a0b7b",
   "metadata": {},
   "source": [
    "|Model layers | input shape | output shape|\n",
    "|---|---|---|\n",
    "|Conv1|(224,224,3)|(112,112,32)|\n",
    "|Encoder|(112,112,32)|bir2_out (56,56,24),<br> bir3_out (28,28,32),<br> bir5_out (14,14,96),<br> bir7_out (7,7,320)|\n",
    "|Decoder|bir2_out (56,56,24),<br> bir3_out (28,28,32),<br> bir5_out (14,14,96),<br> bir7_out (7,7,320)|(224,224,16)|\n",
    "|Convf1 (transpose convolution)<br>{stride = 1, kernel_size = (3,3),<br>activation = Linear}|(224,224,16)|(224,224,8)|\n",
    "|Convf2 (transpose convolution)<br>{stride = 1, kernel_size = (3,3)<br>activation = softmax}|(224,224,8)|(224,224,1)|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e014a392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"QUICKSAL\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"QUICKSAL\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">864</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ QUICKSAL_encoder    │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,843,424</span> │ Conv1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">QUICKSAL_encoder</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,   │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,   │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ QUICKSAL_decoder    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,829,888</span> │ Conv1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">QUICKSAL_decoder</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │            │ QUICKSAL_encoder… │\n",
       "│                     │                   │            │ QUICKSAL_encoder… │\n",
       "│                     │                   │            │ QUICKSAL_encoder… │\n",
       "│                     │                   │            │ QUICKSAL_encoder… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Convf1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span> │ QUICKSAL_decoder… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Convf2              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span> │ Convf1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ softmax_output      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Convf2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Conv1 (\u001b[38;5;33mConv2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m,  │        \u001b[38;5;34m864\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ QUICKSAL_encoder    │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,   │  \u001b[38;5;34m1,843,424\u001b[0m │ Conv1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mQUICKSAL_encoder\u001b[0m)  │ \u001b[38;5;34m24\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m,   │            │                   │\n",
       "│                     │ \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,   │            │                   │\n",
       "│                     │ \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m96\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m320\u001b[0m)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ QUICKSAL_decoder    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │  \u001b[38;5;34m1,829,888\u001b[0m │ Conv1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│ (\u001b[38;5;33mQUICKSAL_decoder\u001b[0m)  │ \u001b[38;5;34m16\u001b[0m)               │            │ QUICKSAL_encoder… │\n",
       "│                     │                   │            │ QUICKSAL_encoder… │\n",
       "│                     │                   │            │ QUICKSAL_encoder… │\n",
       "│                     │                   │            │ QUICKSAL_encoder… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Convf1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │      \u001b[38;5;34m1,152\u001b[0m │ QUICKSAL_decoder… │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)   │ \u001b[38;5;34m8\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Convf2              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │         \u001b[38;5;34m72\u001b[0m │ Convf1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)   │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ softmax_output      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ Convf2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,675,400</span> (14.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,675,400\u001b[0m (14.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,803,656</span> (6.88 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,803,656\u001b[0m (6.88 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,871,744</span> (7.14 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,871,744\u001b[0m (7.14 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# QUICKSAL model\n",
    "inputs = tf.keras.layers.Input((224,224,3))\n",
    "conv1_out = tf.keras.layers.Conv2D(filters = 32,\n",
    "                               kernel_size = 3,\n",
    "                               strides = 2,\n",
    "                               padding = 'same',\n",
    "                               use_bias = False,\n",
    "                               name = 'Conv1')(inputs)\n",
    "\n",
    "# encoder creation\n",
    "encoder = QUICKSAL_encoder(name='QUICKSAL_encoder')\n",
    "_=encoder(conv1_out) # building the encoder layer to be able to load pre-trained weights\n",
    "set_encoder_weights(enc=encoder,mbnet=mbnet) # loading pre-trained weights\n",
    "\n",
    "bir2_out,bir3_out,bir5_out,bir7_out = encoder(conv1_out)\n",
    "\n",
    "# ensure that only the first layer of block 1 of encoder is trainable, rest all non-trainable\n",
    "for layer in encoder._layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "encoder._layers[0]._layers[0].trainable = True\n",
    "\n",
    "# decoder creation\n",
    "decoder = QUICKSAL_decoder(name = 'QUICKSAL_decoder')\n",
    "decoder_out = decoder([conv1_out,bir2_out,bir3_out,bir5_out,bir7_out])\n",
    "\n",
    "# transpose convolution layer to get the output\n",
    "convf1_out = tf.keras.layers.Conv2DTranspose(filters = 8,\n",
    "                                             kernel_size = 3,\n",
    "                                             strides = 1,\n",
    "                                             padding = 'same',\n",
    "                                             use_bias = False, \n",
    "                                             # activation -> Linear\n",
    "                                             name = 'Convf1')(decoder_out)\n",
    "\n",
    "convf2_out = tf.keras.layers.Conv2DTranspose(filters = 1,\n",
    "                                             kernel_size = 3,\n",
    "                                             strides = 1,\n",
    "                                             padding = 'same',\n",
    "                                             use_bias = False,\n",
    "                                             activation = 'softmax',\n",
    "                                             name = 'Convf2')(convf1_out)\n",
    "\n",
    "# for mixed precision training, we need softmax output to be tf.float32\n",
    "outputs = tf.keras.layers.Activation('softmax',dtype = tf.float32, name = 'softmax_output')(convf2_out)\n",
    "\n",
    "QUICKSAL = tf.keras.models.Model(inputs=inputs,outputs=outputs,name='QUICKSAL')\n",
    "QUICKSAL.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12b73c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,layer in enumerate(QUICKSAL._layers):\n",
    "    print(layer,layer.trainable) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e056f3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# layers in encoder\n",
    "for i,layer in enumerate(QUICKSAL._layers[2]._layers):\n",
    "    print(layer,layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da69fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# layers in block 1 of encoder\n",
    "for i,layer in enumerate(QUICKSAL._layers[2]._layers[0]._layers):\n",
    "    print(layer,layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578d41a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "img_list = os.listdir('MSRA10K_Imgs_GT/Imgs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04501fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_img(img_path,shape = (224,224),normalize = True):\n",
    "    img = tf.io.read_file(img_path)\n",
    "    img = tf.io.decode_image(img)\n",
    "    img = tf.image.resize(img,size = shape)\n",
    "    img = tf.expand_dims(img,axis=0)\n",
    "    if normalize:\n",
    "        img = img/255.0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b797ee42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "img_no = random.choice(img_list)[:-4]\n",
    "test_img = process_img(f'MSRA10K_Imgs_GT/Imgs/{img_no}.jpg')\n",
    "test_label = process_img(f'MSRA10K_Imgs_GT/Imgs/{img_no}.png')\n",
    "\n",
    "fig,axs = plt.subplots(1,2,figsize = (8,6))\n",
    "\n",
    "axs[0].imshow(tf.squeeze(test_img))\n",
    "axs[0].axis('off')\n",
    "axs[1].imshow(tf.squeeze(test_label),cmap='gray')\n",
    "axs[1].axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144d5fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a77b001",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_img = QUICKSAL.predict(test_img,verbose = 0)\n",
    "fig,axs = plt.subplots(1,2,figsize = (8,6))\n",
    "\n",
    "axs[0].imshow(tf.squeeze(test_img))\n",
    "axs[0].axis('off')\n",
    "axs[1].imshow(tf.squeeze(pred_img),cmap='gray')\n",
    "axs[1].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad868fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_img.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aec1e30",
   "metadata": {},
   "source": [
    "***-- CONTD IN NEXT NOTEBOOK --***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
