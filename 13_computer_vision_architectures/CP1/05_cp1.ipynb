{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ff0b385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DL needs\n",
    "import tensorflow as tf\n",
    "import keras as kr\n",
    "\n",
    "# Data needs\n",
    "import pandas as pd\n",
    "\n",
    "# Numerical computation needs\n",
    "import numpy as np\n",
    "\n",
    "# plotting needs\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n",
    "\n",
    "# ensuring reproducibility\n",
    "random_seed=42\n",
    "tf.random.set_seed(random_seed)\n",
    "\n",
    "# file needs\n",
    "import os\n",
    "\n",
    "# model imports\n",
    "from models.model import BIR_BLOCK,QUICKSAL_encoder,InceptionBlock,QUICKSAL_decoder,QUICKSAL,mbnet\n",
    "\n",
    "# handling warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30626734",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = 'MSRA10K_Imgs_GT/Imgs'\n",
    "all_data = os.listdir(DATASET_PATH)\n",
    "\n",
    "data = [img for img in all_data if img.endswith('jpg')]\n",
    "labels = [img for img in all_data if img.endswith('png')]\n",
    "\n",
    "print(f\"total data images: {len(data)}\\ntotal labels: {len(labels)}\\n\")\n",
    "\n",
    "# sorting data and labels\n",
    "data.sort(key=lambda filename: int(filename[:-4]))\n",
    "labels.sort(key=lambda filename: int(filename[:-4]))\n",
    "print(f\"data: {data[:5]}\\nlabels: {labels[:5]}\")\n",
    "\n",
    "# Full paths\n",
    "data_paths = [os.path.join(DATASET_PATH, img) for img in data]\n",
    "label_paths = [os.path.join(DATASET_PATH, label) for label in labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbba084",
   "metadata": {},
   "source": [
    "**Train-Val-Test split**\n",
    "* The paper uses a train-val-test split of 0.8,0.1,0.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4183b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_len = len(data_paths)\n",
    "\n",
    "train_size = int(0.8*total_len)\n",
    "val_size = int(0.1*total_len)\n",
    "test_size = total_len - train_size -val_size # to cover rounding errors\n",
    "\n",
    "# train data/labels\n",
    "train_data_paths = data_paths[:train_size]\n",
    "train_label_paths = label_paths[:train_size]\n",
    "\n",
    "# valid data/labels\n",
    "val_data_paths = data_paths[train_size:train_size+val_size]\n",
    "val_label_paths = label_paths[train_size:train_size+val_size]\n",
    "\n",
    "# test data/labels\n",
    "test_data_paths = data_paths[train_size+val_size:]\n",
    "test_label_paths = label_paths[train_size+val_size:]\n",
    "\n",
    "print(f'Train data size: {len(train_data_paths)}\\nTrain label size: {len(train_label_paths)}\\n')\n",
    "print(f'Val data size: {len(val_data_paths)}\\nTrain label size: {len(val_label_paths)}\\n')\n",
    "print(f'Test data size: {len(val_data_paths)}\\nTrain label size: {len(val_label_paths)}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e9f593",
   "metadata": {},
   "source": [
    "**Creating pre-processing function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9b6e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_img(img_path):\n",
    "    img = tf.io.read_file(img_path)\n",
    "    img = tf.io.decode_jpeg(img,channels = 3)\n",
    "\n",
    "    img_shape = [224,224]\n",
    "    # resizing image\n",
    "    img = tf.image.resize(img,size = img_shape)\n",
    "\n",
    "    # normalizing image\n",
    "    img = img/255.0\n",
    "    \n",
    "    # expanding dimensions and type-casting to float32\n",
    "    img = tf.cast(img,tf.float32)\n",
    "    return img  \n",
    "\n",
    "def load_and_preprocess_label(img_path):\n",
    "    img = tf.io.read_file(img_path)\n",
    "    img = tf.io.decode_png(img,channels = 1)\n",
    "\n",
    "    img_shape = [224,224]\n",
    "    # resizing image\n",
    "    img = tf.image.resize(img,size = img_shape)\n",
    "        \n",
    "    # expanding dimensions and type-casting to float32\n",
    "    img = tf.cast(img,tf.float32)\n",
    "    return img  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22859b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCHSIZE = 8\n",
    "\n",
    "# Create train dataset\n",
    "train_data_ds = tf.data.Dataset.from_tensor_slices(train_data_paths)\n",
    "train_label_ds = tf.data.Dataset.from_tensor_slices(train_label_paths)\n",
    "\n",
    "# Map preprocessing \n",
    "train_data_ds = train_data_ds.map(load_and_preprocess_img,num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_label_ds = train_label_ds.map(load_and_preprocess_label,num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "# # Zip data and label together\n",
    "train_ds = tf.data.Dataset.zip((train_data_ds, train_label_ds))\n",
    "\n",
    "# # Shuffle, batch, prefetch\n",
    "train_ds = train_ds.shuffle(buffer_size=1000).batch(batch_size=BATCHSIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# --- xxx ---\n",
    "\n",
    "# Create val dataset\n",
    "val_data_ds = tf.data.Dataset.from_tensor_slices(val_data_paths)\n",
    "val_label_ds = tf.data.Dataset.from_tensor_slices(val_label_paths)\n",
    "\n",
    "# Map preprocessing \n",
    "val_data_ds = val_data_ds.map(load_and_preprocess_img,num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_label_ds = val_label_ds.map(load_and_preprocess_label,num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "# # Zip data and label together\n",
    "val_ds = tf.data.Dataset.zip((val_data_ds, val_label_ds))\n",
    "\n",
    "# # Shuffle, batch, prefetch\n",
    "val_ds = val_ds.shuffle(buffer_size=1000).batch(batch_size=BATCHSIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# --- xxx ---\n",
    "\n",
    "# Create val dataset\n",
    "test_data_ds = tf.data.Dataset.from_tensor_slices(test_data_paths)\n",
    "test_label_ds = tf.data.Dataset.from_tensor_slices(test_label_paths)\n",
    "\n",
    "# Map preprocessing \n",
    "test_data_ds = test_data_ds.map(load_and_preprocess_img,num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_label_ds = test_label_ds.map(load_and_preprocess_label,num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "# # Zip data and label together\n",
    "test_ds = tf.data.Dataset.zip((test_data_ds, test_label_ds))\n",
    "\n",
    "# # Shuffle, batch, prefetch\n",
    "test_ds = test_ds.shuffle(buffer_size=1000).batch(batch_size=BATCHSIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# --- xxx ---\n",
    "\n",
    "\n",
    "# # --- xxx ---\n",
    "train_ds, val_ds, test_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2b0212",
   "metadata": {},
   "source": [
    "**Visualizing an image from the dataloader created**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50951bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Take one batch from the dataset\n",
    "for data, label in train_ds.take(1):  # Take 1 batch from the dataset\n",
    "    # data and label are tensors; you can convert them to numpy arrays if needed\n",
    "    image = data[0].numpy()  # Assuming the batch size is at least 1\n",
    "    label_image = label[0].numpy()\n",
    "\n",
    "    # Plot the image and its corresponding label\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    # Plot original image\n",
    "    ax[0].imshow(image)\n",
    "    ax[0].set_title(\"Image\")\n",
    "    ax[0].axis('off')\n",
    "\n",
    "    # Plot label image\n",
    "    ax[1].imshow(label_image,cmap='gray')\n",
    "    ax[1].set_title(\"Label\")\n",
    "    ax[1].axis('off')\n",
    "\n",
    "    plt.show()\n",
    "    break  # We only want to show one example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8849eead",
   "metadata": {},
   "outputs": [],
   "source": [
    "quicksal = QUICKSAL()\n",
    "quicksal.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525c914e",
   "metadata": {},
   "source": [
    "**13. Creating callbacks, allow mixed precision training and compile the model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691b1a13",
   "metadata": {},
   "source": [
    "**Callbacks**\n",
    "* Model Checkpoint callback (path: /models/checkpoints/) to save the best model (based on val-loss)\n",
    "* Early Stopping callback (patience = 10)\n",
    "* CyclicLR callback with learning rate in range(0.001,0.00001)\n",
    "\n",
    "**Compile**\n",
    "* Optimizer: Adam()\n",
    "* Loss function: MAE\n",
    "* Metrics: MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c98079f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. ModelCheckpoint callback\n",
    "checkpoint_path = 'models/checkpoints/best_model.keras'\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = checkpoint_path,\n",
    "    monitor = 'val_loss',\n",
    "    verbose = 1,\n",
    "    save_best_only = True, # save only the best\n",
    "    save_weights_only = False # save entire model\n",
    ")\n",
    "\n",
    "# 2. EarlyStopping callback\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 3. CyclicLR callback\n",
    "class CyclicLR(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, base_lr=0.0001, max_lr=0.001, step_size=2000, mode='triangular'):\n",
    "        super(CyclicLR, self).__init__()\n",
    "        self.base_lr = base_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.step_size = step_size\n",
    "        self.mode = mode\n",
    "        self.iterations = 0\n",
    "        self.history = {}\n",
    "\n",
    "    def clr(self):\n",
    "        cycle = tf.floor(1 + self.iterations / (2 * self.step_size))\n",
    "        x = tf.abs(self.iterations / self.step_size - 2 * cycle + 1)\n",
    "        if self.mode == 'triangular':\n",
    "            return self.base_lr + (self.max_lr - self.base_lr) * tf.maximum(0.0, (1 - x))\n",
    "        else:\n",
    "            raise ValueError('Only \"triangular\" mode is supported')\n",
    "\n",
    "    def on_train_batch_begin(self, batch, logs=None):\n",
    "        lr = self.clr()\n",
    "\n",
    "        # safer\n",
    "        if hasattr(self.model.optimizer, 'inner_optimizer'):\n",
    "            optimizer = self.model.optimizer.inner_optimizer\n",
    "        else:\n",
    "            optimizer = self.model.optimizer\n",
    "        \n",
    "        try:\n",
    "            optimizer.learning_rate.assign(lr)\n",
    "        except AttributeError:\n",
    "            optimizer.lr.assign(lr)\n",
    "\n",
    "        self.history.setdefault('lr', []).append(lr.numpy())\n",
    "        self.iterations += 1\n",
    "\n",
    "cyclic_lr_callback = CyclicLR(base_lr=1e-4, max_lr=1e-3, step_size=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d4d39e",
   "metadata": {},
   "source": [
    "**ADDITIONAL Verification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aadc7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn on mixed-precision training\n",
    "tf.keras.mixed_precision.set_global_policy('mixed_float16') # data type policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f37abc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "quicksal.compile(\n",
    "    loss = 'mae',\n",
    "    optimizer = tf.keras.optimizers.Adam(),\n",
    "    metrics = ['mae']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79751321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = quicksal.fit(\n",
    "#     train_ds,\n",
    "#     steps_per_epoch = int(0.1*len(train_ds)),\n",
    "#     validation_data = val_ds,\n",
    "#     validation_steps = int(0.1*len(val_ds)),\n",
    "#     epochs = 2, # max-epochs\n",
    "#     callbacks = [checkpoint_callback,early_stopping_callback,cyclic_lr_callback],\n",
    "#     verbose = 1\n",
    "# )   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d068e8",
   "metadata": {},
   "source": [
    "***-- CONTD IN NEXT NOTEBOOK --***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
